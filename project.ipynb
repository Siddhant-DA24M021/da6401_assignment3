{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "006166dc",
      "metadata": {
        "id": "006166dc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7af70d1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7af70d1a",
        "outputId": "4b654ff8-ca40-4967-c4f4-3551dfc39778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8717b5ee",
      "metadata": {
        "id": "8717b5ee"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "da675966",
      "metadata": {
        "id": "da675966"
      },
      "outputs": [],
      "source": [
        "TRAIN_FilePath = 'dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv'\n",
        "DEV_FilePath = 'dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv'\n",
        "TEST_FilePath = 'dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "JQXJuVJIgUSm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQXJuVJIgUSm",
        "outputId": "dbb8c883-b5d3-41c1-c01c-f77c7a89d29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "TRAIN_FilePath = '/content/drive/My Drive/hi/lexicons/hi.translit.sampled.train.tsv'\n",
        "DEV_FilePath = '/content/drive/My Drive/hi/lexicons/hi.translit.sampled.dev.tsv'\n",
        "TEST_FilePath = '/content/drive/My Drive/hi/lexicons/hi.translit.sampled.test.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "442695ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "442695ab",
        "outputId": "e02fe2d1-5257-44be-96fe-e9c68ef80150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Dataset Size : 44204\n",
            "Dev Dataset Size   : 4358\n",
            "Test Dataset Size  : 4502\n"
          ]
        }
      ],
      "source": [
        "# Load train, dev and test datasets\n",
        "train_df = pd.read_csv(TRAIN_FilePath, sep='\\t', header=None)\n",
        "dev_df = pd.read_csv(DEV_FilePath, sep='\\t', header=None)\n",
        "test_df = pd.read_csv(TEST_FilePath, sep='\\t', header=None)\n",
        "\n",
        "\n",
        "# Renaming the columns\n",
        "train_df.columns = ['devanagari', 'latin', 'frequency']\n",
        "dev_df.columns = ['devanagari', 'latin', 'frequency']\n",
        "test_df.columns = ['devanagari', 'latin', 'frequency']\n",
        "\n",
        "# Dataset Sizes\n",
        "print(f\"Train Dataset Size : {train_df.shape[0]}\\nDev Dataset Size   : {dev_df.shape[0]}\\nTest Dataset Size  : {test_df.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3bc01713",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3bc01713",
        "outputId": "61c5fdf2-f0c5-4cb5-8b70-9879d6b4fbec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 44204,\n  \"fields\": [\n    {\n      \"column\": \"devanagari\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25000,\n        \"samples\": [\n          \"\\u091a\\u093e\\u0902\\u092a\\u093e\",\n          \"\\u0938\\u094d\\u091f\\u0949\\u0915\\u0939\\u094b\\u092e\",\n          \"\\u0924\\u093e\\u0932\\u093e\\u092c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latin\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41344,\n        \"samples\": [\n          \"nishanebaazi\",\n          \"champu\",\n          \"bhej\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frequency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          10,\n          4,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6b1863be-9e97-46f2-810b-cf807c4dc64c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>devanagari</th>\n",
              "      <th>latin</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अं</td>\n",
              "      <td>an</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>अंकगणित</td>\n",
              "      <td>ankganit</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>अंकल</td>\n",
              "      <td>uncle</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>अंकुर</td>\n",
              "      <td>ankur</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंकुरण</td>\n",
              "      <td>ankuran</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b1863be-9e97-46f2-810b-cf807c4dc64c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b1863be-9e97-46f2-810b-cf807c4dc64c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b1863be-9e97-46f2-810b-cf807c4dc64c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3bcd24ca-5405-4e16-a5d0-bf91ae0b5b6a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3bcd24ca-5405-4e16-a5d0-bf91ae0b5b6a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3bcd24ca-5405-4e16-a5d0-bf91ae0b5b6a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  devanagari     latin  frequency\n",
              "0         अं        an          3\n",
              "1    अंकगणित  ankganit          3\n",
              "2       अंकल     uncle          4\n",
              "3      अंकुर     ankur          4\n",
              "4     अंकुरण   ankuran          3"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7ce116ff",
      "metadata": {
        "id": "7ce116ff"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.pad_token = \"<pad>\"\n",
        "        self.sos_token = \"<sos>\"\n",
        "        self.eos_token = \"<eos>\"\n",
        "        self.unk_token = \"<unk>\"\n",
        "\n",
        "        # Initialize mappings\n",
        "        self.char2idx = {self.pad_token: 0, self.sos_token: 1, self.eos_token: 2, self.unk_token: 3}\n",
        "        self.idx2char = {0: self.pad_token, 1: self.sos_token, 2: self.eos_token, 3: self.unk_token}\n",
        "        self.vocab_size = 4\n",
        "\n",
        "    def build_vocabulary(self, text_data):\n",
        "        for text in text_data:\n",
        "            text = str(text)\n",
        "            for char in text:\n",
        "                if char not in self.char2idx:\n",
        "                    self.char2idx[char] = self.vocab_size\n",
        "                    self.idx2char[self.vocab_size] = char\n",
        "                    self.vocab_size += 1\n",
        "\n",
        "    def encode(self, text, add_special_tokens=True):\n",
        "        indices = []\n",
        "        text = str(text)\n",
        "        for char in text:\n",
        "            indices.append(self.char2idx.get(char, self.char2idx[self.unk_token]))\n",
        "\n",
        "        if add_special_tokens:\n",
        "            indices = [self.char2idx[self.sos_token]] + indices + [self.char2idx[self.eos_token]]\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def decode(self, indices, remove_special_tokens=True):\n",
        "        chars = []\n",
        "        keys = list(self.idx2char.keys())\n",
        "        for idx in indices:\n",
        "            if isinstance(idx, torch.Tensor):\n",
        "                idx = idx.item()\n",
        "            if idx in keys:\n",
        "                char = self.idx2char[idx]\n",
        "                if remove_special_tokens and char in [self.pad_token, self.sos_token, self.eos_token, self.unk_token]:\n",
        "                    continue\n",
        "                chars.append(char)\n",
        "\n",
        "        return \"\".join(chars)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6b71af2b",
      "metadata": {
        "id": "6b71af2b"
      },
      "outputs": [],
      "source": [
        "class TransliterationDataset(Dataset):\n",
        "    def __init__(self, data_path, src_vocab, tgt_vocab):\n",
        "        df = pd.read_csv(data_path, sep='\\t', header=None)\n",
        "\n",
        "        # Create Dataset\n",
        "        self.source_sequences = []\n",
        "        self.target_sequences = []\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            x_seq = src_vocab.encode(row[1])\n",
        "            y_seq = tgt_vocab.encode(row[0])\n",
        "            self.source_sequences.append(x_seq)\n",
        "            self.target_sequences.append(y_seq)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.source_sequences[idx], dtype=torch.long), torch.tensor(self.target_sequences[idx], dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5fae80fe",
      "metadata": {
        "id": "5fae80fe"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    src_batch = [item[0] for item in batch]\n",
        "    tgt_batch = [item[1] for item in batch]\n",
        "\n",
        "    # Pad sequences\n",
        "    src_batch_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_batch_padded = pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    return src_batch_padded, tgt_batch_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f5a9c7db",
      "metadata": {
        "id": "f5a9c7db"
      },
      "outputs": [],
      "source": [
        "# Build Source and Target Vocabularies\n",
        "src_vocab = Vocabulary()\n",
        "tgt_vocab = Vocabulary()\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_FilePath, sep='\\t', header=None)\n",
        "src_text = []\n",
        "tgt_text = []\n",
        "for idx, row in train_df.iterrows():\n",
        "    src_text.append(row[1])\n",
        "    tgt_text.append(row[0])\n",
        "\n",
        "src_vocab.build_vocabulary(src_text)\n",
        "tgt_vocab.build_vocabulary(tgt_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9c05d023",
      "metadata": {
        "id": "9c05d023"
      },
      "outputs": [],
      "source": [
        "# Train, Test and Dev (Validation) Dataset and Dataloaders\n",
        "train_dataset = TransliterationDataset(TRAIN_FilePath, src_vocab, tgt_vocab)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "dev_dataset = TransliterationDataset(DEV_FilePath, src_vocab, tgt_vocab)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "test_dataset = TransliterationDataset(TEST_FilePath, src_vocab, tgt_vocab)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "256803ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "256803ad",
        "outputId": "19f50ac0-a046-40f1-83de-d7945bebd9e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs shape: torch.Size([32, 14])\n",
            "Targets shape: torch.Size([32, 13])\n",
            "Sample input: tensor([ 1,  6,  4, 23, 10,  6,  9,  4,  2,  0,  0,  0,  0,  0])\n",
            "Sample target: tensor([ 1,  6, 21, 29, 12,  6, 10, 21,  2,  0,  0,  0,  0])\n",
            "kamukta\n",
            "कामुकता\n"
          ]
        }
      ],
      "source": [
        "# Inspect if dataloader is created as desired\n",
        "for batch in train_loader:\n",
        "    inputs, targets = batch\n",
        "\n",
        "    print(\"Inputs shape:\", inputs.shape)\n",
        "    print(\"Targets shape:\", targets.shape)\n",
        "\n",
        "    # Check one sample\n",
        "    print(\"Sample input:\", inputs[0])\n",
        "    print(\"Sample target:\", targets[0])\n",
        "    print(src_vocab.decode(inputs[0]))\n",
        "    print(tgt_vocab.decode(targets[0]))\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93376085",
      "metadata": {
        "id": "93376085"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9576e288",
      "metadata": {
        "id": "9576e288"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers=1, cell_type=\"RNN\", dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        if num_layers == 1:\n",
        "            dropout = 0\n",
        "\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "        # Embedding Layer\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "        # Recurrent Layer\n",
        "        if cell_type == \"LSTM\":\n",
        "            self.recurrent_layer = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.recurrent_layer = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
        "        else: # Default (RNN)\n",
        "            self.recurrent_layer = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input: batch_size x seq_len\n",
        "\n",
        "        embeddings = self.embedding(input)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        if self.cell_type == 'LSTM':\n",
        "            outputs, (hidden, cell) = self.recurrent_layer(embeddings)\n",
        "            return outputs, (hidden, cell)\n",
        "        else:\n",
        "            outputs, hidden = self.recurrent_layer(embeddings)\n",
        "            return outputs, hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d00065e3",
      "metadata": {
        "id": "d00065e3"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, embedding_size, hidden_size, num_layers=1, cell_type=\"RNN\", dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        if num_layers == 1:\n",
        "            dropout = 0\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "        # Embedding Layer\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Recurrent Layer\n",
        "        if cell_type == \"LSTM\":\n",
        "            self.recurrent_layer = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.recurrent_layer = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
        "        else: # Default (RNN)\n",
        "            self.recurrent_layer = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "\n",
        "        input = input.unsqueeze(1)\n",
        "        embeddings = self.embedding(input)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            hidden, cell = hidden\n",
        "            outputs, (hidden, cell) = self.recurrent_layer(embeddings, (hidden, cell))\n",
        "            hidden = (hidden, cell)\n",
        "        else:\n",
        "            outputs, hidden = self.recurrent_layer(embeddings, hidden)\n",
        "\n",
        "        outputs = outputs.squeeze(1)\n",
        "        prediction = self.fc_out(outputs)\n",
        "        return prediction, hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "54eefa93",
      "metadata": {
        "id": "54eefa93"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        tgt_len = tgt.shape[1]\n",
        "        tgt_vocab_size = self.decoder.output_size\n",
        "\n",
        "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
        "\n",
        "        if self.encoder.cell_type == 'LSTM':\n",
        "            encoder_outputs, (hidden, cell) = self.encoder(src)\n",
        "            decoder_hidden = (hidden, cell)\n",
        "        else:\n",
        "            encoder_outputs, hidden = self.encoder(src)\n",
        "            decoder_hidden = hidden\n",
        "\n",
        "        decoder_input = tgt[:, 0]\n",
        "        for t in range(1, tgt_len):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            outputs[:, t] = decoder_output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top = decoder_output.argmax(1)\n",
        "            decoder_input = tgt[:, t] if teacher_force else top\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "644043a4",
      "metadata": {
        "id": "644043a4"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, criterion, clip=1.0):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, tgt) in enumerate(train_loader):\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, tgt)\n",
        "\n",
        "        # Reshape output and target for loss calculation\n",
        "        # output: [batch_size, tgt_len, output_dim]\n",
        "        # tgt: [batch_size, tgt_len]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)  # Remove first token (SOS)\n",
        "        tgt = tgt[:, 1:].reshape(-1)  # Remove first token (SOS)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, tgt)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Batch {i+1}/{len(train_loader)} | Loss: {loss.item():.4f}')\n",
        "\n",
        "    return epoch_loss / len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5cd8bc54",
      "metadata": {
        "id": "5cd8bc54"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (src, tgt) in enumerate(val_loader):\n",
        "            src = src.to(device)\n",
        "            tgt = tgt.to(device)\n",
        "\n",
        "            output = model(src, tgt, teacher_forcing_ratio=0)  # No teacher forcing during evaluation\n",
        "\n",
        "            # Reshape output and target for loss calculation\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(output, tgt)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "53350c2e",
      "metadata": {
        "id": "53350c2e"
      },
      "outputs": [],
      "source": [
        "def transliterate(model, src_text, src_vocab, tgt_vocab, device, max_length=100):\n",
        "    model.eval()\n",
        "\n",
        "    # Convert source text to tensor\n",
        "    src_indices = src_vocab.encode(src_text)\n",
        "    src_tensor = torch.tensor(src_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # Get encoder outputs\n",
        "    with torch.no_grad():\n",
        "        if model.encoder.cell_type == 'LSTM':\n",
        "            encoder_outputs, (hidden, cell) = model.encoder(src_tensor)\n",
        "            decoder_hidden = (hidden, cell)\n",
        "        else:\n",
        "            encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "            decoder_hidden = hidden\n",
        "\n",
        "    # Start with SOS token\n",
        "    decoder_input = torch.tensor([tgt_vocab.char2idx[tgt_vocab.sos_token]], device=device)\n",
        "\n",
        "    result_indices = [tgt_vocab.char2idx[tgt_vocab.sos_token]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        with torch.no_grad():\n",
        "            decoder_output, decoder_hidden = model.decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "        # Get the most likely next character\n",
        "        top_token = decoder_output.argmax(1).item()\n",
        "        result_indices.append(top_token)\n",
        "\n",
        "        # Stop if EOS token\n",
        "        if top_token == tgt_vocab.char2idx[tgt_vocab.eos_token]:\n",
        "            break\n",
        "\n",
        "        # Use predicted token as next input\n",
        "        decoder_input = torch.tensor([top_token], device=device)\n",
        "\n",
        "    # Convert indices to text\n",
        "    result_text = tgt_vocab.decode(result_indices)\n",
        "\n",
        "    return result_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1e18e6aa",
      "metadata": {
        "id": "1e18e6aa"
      },
      "outputs": [],
      "source": [
        "INPUT_SIZE = src_vocab.vocab_size\n",
        "OUTPUT_SIZE = tgt_vocab.vocab_size\n",
        "EMBEDDING_SIZE = 256\n",
        "HIDDEN_SIZE = 512\n",
        "NUM_LAYERS = 2\n",
        "CELL_TYPE = \"LSTM\"  # Options: \"RNN\", \"LSTM\", \"GRU\"\n",
        "DROPOUT = 0.2\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Initialize encoder, decoder, and seq2seq model\n",
        "encoder = Encoder(\n",
        "    input_size=INPUT_SIZE,\n",
        "    embedding_size=EMBEDDING_SIZE,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    cell_type=CELL_TYPE,\n",
        "    dropout=DROPOUT\n",
        ")\n",
        "\n",
        "decoder = Decoder(\n",
        "    output_size=OUTPUT_SIZE,\n",
        "    embedding_size=EMBEDDING_SIZE,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    cell_type=CELL_TYPE,\n",
        "    dropout=DROPOUT\n",
        ")\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding token (index 0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "fcb19b1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcb19b1d",
        "outputId": "e58c30ef-f958-439e-83fc-5d96c6523805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for 10 epochs...\n",
            "Epoch 1/10\n",
            "Batch 100/1382 | Loss: 3.0889\n",
            "Batch 200/1382 | Loss: 2.6197\n",
            "Batch 300/1382 | Loss: 2.6491\n",
            "Batch 400/1382 | Loss: 2.0562\n",
            "Batch 500/1382 | Loss: 1.6644\n",
            "Batch 600/1382 | Loss: 1.2051\n",
            "Batch 700/1382 | Loss: 1.1606\n",
            "Batch 800/1382 | Loss: 1.3630\n",
            "Batch 900/1382 | Loss: 1.0955\n",
            "Batch 1000/1382 | Loss: 0.8668\n",
            "Batch 1100/1382 | Loss: 1.4716\n",
            "Batch 1200/1382 | Loss: 0.8982\n",
            "Batch 1300/1382 | Loss: 0.9838\n",
            "Train Loss: 1.6242 | Valid Loss: 1.1897\n",
            "Model saved!\n",
            "Epoch 2/10\n",
            "Batch 100/1382 | Loss: 1.1630\n",
            "Batch 200/1382 | Loss: 0.9476\n",
            "Batch 300/1382 | Loss: 0.5444\n",
            "Batch 400/1382 | Loss: 0.7372\n",
            "Batch 500/1382 | Loss: 0.5402\n",
            "Batch 600/1382 | Loss: 0.6457\n",
            "Batch 700/1382 | Loss: 0.7539\n",
            "Batch 800/1382 | Loss: 0.7224\n",
            "Batch 900/1382 | Loss: 0.6856\n",
            "Batch 1000/1382 | Loss: 0.6379\n",
            "Batch 1100/1382 | Loss: 0.5698\n",
            "Batch 1200/1382 | Loss: 0.4394\n",
            "Batch 1300/1382 | Loss: 0.5429\n",
            "Train Loss: 0.7176 | Valid Loss: 1.0699\n",
            "Model saved!\n",
            "Epoch 3/10\n",
            "Batch 100/1382 | Loss: 0.4948\n",
            "Batch 200/1382 | Loss: 0.4673\n",
            "Batch 300/1382 | Loss: 0.7042\n",
            "Batch 400/1382 | Loss: 0.6599\n",
            "Batch 500/1382 | Loss: 0.5968\n",
            "Batch 600/1382 | Loss: 0.5509\n",
            "Batch 700/1382 | Loss: 0.4595\n",
            "Batch 800/1382 | Loss: 0.7375\n",
            "Batch 900/1382 | Loss: 0.4551\n",
            "Batch 1000/1382 | Loss: 0.6108\n",
            "Batch 1100/1382 | Loss: 0.5570\n",
            "Batch 1200/1382 | Loss: 0.3321\n",
            "Batch 1300/1382 | Loss: 0.5568\n",
            "Train Loss: 0.5511 | Valid Loss: 1.0033\n",
            "Model saved!\n",
            "Epoch 4/10\n",
            "Batch 100/1382 | Loss: 0.3492\n",
            "Batch 200/1382 | Loss: 0.3622\n",
            "Batch 300/1382 | Loss: 0.4430\n",
            "Batch 400/1382 | Loss: 0.2890\n",
            "Batch 500/1382 | Loss: 0.5954\n",
            "Batch 600/1382 | Loss: 0.3807\n",
            "Batch 700/1382 | Loss: 0.5135\n",
            "Batch 800/1382 | Loss: 0.4187\n",
            "Batch 900/1382 | Loss: 0.4446\n",
            "Batch 1000/1382 | Loss: 0.3136\n",
            "Batch 1100/1382 | Loss: 0.3804\n",
            "Batch 1200/1382 | Loss: 0.6139\n",
            "Batch 1300/1382 | Loss: 0.4878\n",
            "Train Loss: 0.4492 | Valid Loss: 1.0564\n",
            "Epoch 5/10\n",
            "Batch 100/1382 | Loss: 0.3526\n",
            "Batch 200/1382 | Loss: 0.4490\n",
            "Batch 300/1382 | Loss: 0.3334\n",
            "Batch 400/1382 | Loss: 0.2933\n",
            "Batch 500/1382 | Loss: 0.5047\n",
            "Batch 600/1382 | Loss: 0.2688\n",
            "Batch 700/1382 | Loss: 0.2482\n",
            "Batch 800/1382 | Loss: 0.2541\n",
            "Batch 900/1382 | Loss: 0.2773\n",
            "Batch 1000/1382 | Loss: 0.3569\n",
            "Batch 1100/1382 | Loss: 0.3683\n",
            "Batch 1200/1382 | Loss: 0.2921\n",
            "Batch 1300/1382 | Loss: 0.4625\n",
            "Train Loss: 0.3793 | Valid Loss: 1.0724\n",
            "Epoch 6/10\n",
            "Batch 100/1382 | Loss: 0.3216\n",
            "Batch 200/1382 | Loss: 0.2113\n",
            "Batch 300/1382 | Loss: 0.2943\n",
            "Batch 400/1382 | Loss: 0.2259\n",
            "Batch 500/1382 | Loss: 0.3350\n",
            "Batch 600/1382 | Loss: 0.2515\n",
            "Batch 700/1382 | Loss: 0.4953\n",
            "Batch 800/1382 | Loss: 0.3820\n",
            "Batch 900/1382 | Loss: 0.3736\n",
            "Batch 1000/1382 | Loss: 0.2708\n",
            "Batch 1100/1382 | Loss: 0.2125\n",
            "Batch 1200/1382 | Loss: 0.3760\n",
            "Batch 1300/1382 | Loss: 0.5148\n",
            "Train Loss: 0.3296 | Valid Loss: 1.0833\n",
            "Epoch 7/10\n",
            "Batch 100/1382 | Loss: 0.3913\n",
            "Batch 200/1382 | Loss: 0.1838\n",
            "Batch 300/1382 | Loss: 0.3053\n",
            "Batch 400/1382 | Loss: 0.3295\n",
            "Batch 500/1382 | Loss: 0.2810\n",
            "Batch 600/1382 | Loss: 0.4141\n",
            "Batch 700/1382 | Loss: 0.1871\n",
            "Batch 800/1382 | Loss: 0.4170\n",
            "Batch 900/1382 | Loss: 0.1876\n",
            "Batch 1000/1382 | Loss: 0.2093\n",
            "Batch 1100/1382 | Loss: 0.2897\n",
            "Batch 1200/1382 | Loss: 0.2974\n",
            "Batch 1300/1382 | Loss: 0.3348\n",
            "Train Loss: 0.2876 | Valid Loss: 1.0992\n",
            "Epoch 8/10\n",
            "Batch 100/1382 | Loss: 0.2037\n",
            "Batch 200/1382 | Loss: 0.1584\n",
            "Batch 300/1382 | Loss: 0.2348\n",
            "Batch 400/1382 | Loss: 0.3320\n",
            "Batch 500/1382 | Loss: 0.4688\n",
            "Batch 600/1382 | Loss: 0.2167\n",
            "Batch 700/1382 | Loss: 0.1707\n",
            "Batch 800/1382 | Loss: 0.1688\n",
            "Batch 900/1382 | Loss: 0.2209\n",
            "Batch 1000/1382 | Loss: 0.2808\n",
            "Batch 1100/1382 | Loss: 0.2310\n",
            "Batch 1200/1382 | Loss: 0.3087\n",
            "Batch 1300/1382 | Loss: 0.3407\n",
            "Train Loss: 0.2592 | Valid Loss: 1.1266\n",
            "Epoch 9/10\n",
            "Batch 100/1382 | Loss: 0.1214\n",
            "Batch 200/1382 | Loss: 0.2310\n",
            "Batch 300/1382 | Loss: 0.3227\n",
            "Batch 400/1382 | Loss: 0.2615\n",
            "Batch 500/1382 | Loss: 0.2991\n",
            "Batch 600/1382 | Loss: 0.1846\n",
            "Batch 700/1382 | Loss: 0.1913\n",
            "Batch 800/1382 | Loss: 0.1454\n",
            "Batch 900/1382 | Loss: 0.1443\n",
            "Batch 1000/1382 | Loss: 0.2236\n",
            "Batch 1100/1382 | Loss: 0.3266\n",
            "Batch 1200/1382 | Loss: 0.2361\n",
            "Batch 1300/1382 | Loss: 0.1723\n",
            "Train Loss: 0.2369 | Valid Loss: 1.1810\n",
            "Epoch 10/10\n",
            "Batch 100/1382 | Loss: 0.2311\n",
            "Batch 200/1382 | Loss: 0.2203\n",
            "Batch 300/1382 | Loss: 0.1047\n",
            "Batch 400/1382 | Loss: 0.1935\n",
            "Batch 500/1382 | Loss: 0.3265\n",
            "Batch 600/1382 | Loss: 0.2541\n",
            "Batch 700/1382 | Loss: 0.3303\n",
            "Batch 800/1382 | Loss: 0.2577\n",
            "Batch 900/1382 | Loss: 0.1322\n",
            "Batch 1000/1382 | Loss: 0.1973\n",
            "Batch 1100/1382 | Loss: 0.1829\n",
            "Batch 1200/1382 | Loss: 0.3194\n",
            "Batch 1300/1382 | Loss: 0.2805\n",
            "Train Loss: 0.2231 | Valid Loss: 1.1817\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "print(f\"Starting training for {NUM_EPOCHS} epochs...\")\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "\n",
        "    # Train model\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "\n",
        "    # Evaluate model\n",
        "    valid_loss = evaluate(model, dev_loader, criterion)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best_transliteration_model.pt')\n",
        "        print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ecc9e2fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecc9e2fe",
        "outputId": "9ea1a952-73a2-4b3e-b4d0-2bf6dcfd0f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Accuracy: 0.3634\n"
          ]
        }
      ],
      "source": [
        "# Accuracy calculation function\n",
        "def calculate_accuracy(model, data_loader, src_vocab, tgt_vocab, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in data_loader:\n",
        "            src = src.to(device)\n",
        "            tgt = tgt.to(device)\n",
        "\n",
        "            batch_size = src.shape[0]\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                # Get source text and actual target text\n",
        "                src_indices = src[i].tolist()\n",
        "                src_text = src_vocab.decode(src_indices)\n",
        "                actual_tgt_text = tgt_vocab.decode(tgt[i].tolist())\n",
        "\n",
        "                # Get predicted transliteration\n",
        "                predicted_tgt_text = transliterate(model, src_text, src_vocab, tgt_vocab, device)\n",
        "\n",
        "                # Check if prediction matches\n",
        "                if predicted_tgt_text == actual_tgt_text:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "# Calculate accuracy on test set\n",
        "test_accuracy = calculate_accuracy(model, test_loader, src_vocab, tgt_vocab, device)\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1800c250",
      "metadata": {
        "id": "1800c250"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
